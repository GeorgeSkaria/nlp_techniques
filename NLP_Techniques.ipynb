{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN5gA4VLMjfz",
        "outputId": "9eef4f3f-0318-4fe0-d85f-a2b50291c183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "2023-08-06 05:47:12.822936: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.5.0) (3.5.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BAG OF WORDS**\n"
      ],
      "metadata": {
        "id": "AHcInZeMI8ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Category:\n",
        "  BOOKS=\"BOOKS\"\n",
        "  CLOTHING=\"CLOTHING\"\n",
        "\n",
        "\n",
        "train_x=['i love the book','this is a great book ','the fit is great','i love the shoes']\n",
        "train_y=[Category.BOOKS,Category.BOOKS,Category.CLOTHING,Category.CLOTHING]\n"
      ],
      "metadata": {
        "id": "WBl-GDi3-nEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpE_z1YJDeXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLrZeg4B93r1",
        "outputId": "488625bc-ba15-423f-fad9-e520cbd42d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['book' 'fit' 'great' 'is' 'love' 'shoes' 'the' 'this']\n",
            "[[1 0 0 0 1 0 1 0]\n",
            " [1 0 1 1 0 0 0 1]\n",
            " [0 1 1 1 0 0 1 0]\n",
            " [0 0 0 0 1 1 1 0]]\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer=CountVectorizer(binary=True)\n",
        "train_x_vectors =vectorizer.fit_transform(train_x)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(train_x_vectors.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we create an instance of the CountVectorizer class, which allows us to convert the text data into a bag-of-words representation.\n",
        "The fit_transform method is the key step that does two things:\n",
        "\n",
        "Fit: It analyzes the input text data (text_data) and builds a vocabulary of all the unique words (tokens) present in the data. It assigns a unique integer index to each word in the vocabulary.\n",
        "\n",
        "Transform: It converts the input text data into a matrix representation, where each row corresponds to a document, and each column corresponds to a word in the vocabulary. The entries in the matrix represent the count of each word in the corresponding document.\n"
      ],
      "metadata": {
        "id": "6xsgT7uk8Hui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "clf_svm=svm.SVC(kernel='linear')\n",
        "clf_svm.fit(train_x_vectors, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "f2TyYvHWC_SV",
        "outputId": "af0e089b-52cf-4ae0-d676-948bb18ac6a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x=vectorizer.transform(['book is very important'])\n",
        "clf_svm.predict(test_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1ueEnOxAPyM",
        "outputId": "a4e19ecb-31f3-459f-a011-189d81021d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['BOOKS'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x=vectorizer.transform(['wear shoes please'])\n",
        "clf_svm.predict(test_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co5eTExfAdfO",
        "outputId": "7cec3129-0ebe-46bd-c1cb-11304f62c652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CLOTHING'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer=CountVectorizer(binary=True,ngram_range=(1,2))\n",
        "train_x_vectors =vectorizer.fit_transform(train_x)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(train_x_vectors.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYkHKtEMBeG8",
        "outputId": "8860cb6b-68e7-4860-a5ef-fc288bf08e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['book' 'fit' 'fit is' 'great' 'great book' 'is' 'is great' 'love'\n",
            " 'love the' 'shoes' 'the' 'the book' 'the fit' 'the shoes' 'this'\n",
            " 'this is']\n",
            "[[1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0]\n",
            " [1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1]\n",
            " [0 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WORD VECTORS**"
      ],
      "metadata": {
        "id": "01wTxYFgJUKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load('en_core_web_md')"
      ],
      "metadata": {
        "id": "6f-Ndkq7JX6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs= [nlp(text) for text in train_x]\n",
        "print(docs)\n",
        "train_x_word_vectors=[x.vector for x in docs]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYDrcwMnNIdh",
        "outputId": "9aabb548-2292-43b0-bf5d-f6ee3205165f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[i love the book, this is a great book , the fit is great, i love the shoes]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96_KYOwwY-36",
        "outputId": "e361c852-c12d-4d62-d523-f99ab36b28a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3.9804751e-01 -1.7059250e+00 -9.0664995e-01 -4.5425000e+00\n",
            " -1.1165801e+00 -2.9151249e+00  3.1752450e+00  4.0887251e+00\n",
            " -3.4474750e+00  2.3840599e+00  6.4857249e+00  2.3083498e+00\n",
            " -8.6464500e+00  2.0437698e+00  2.2699749e+00 -1.0261000e+00\n",
            "  4.0915399e+00 -7.4801493e-01  1.1435002e-01 -1.9810501e+00\n",
            "  1.3855026e+00  1.7070000e+00 -2.9752648e+00 -1.9328325e+00\n",
            " -1.4255500e+00 -2.0426226e+00 -3.7064652e+00 -4.3784651e-01\n",
            " -2.0860374e+00  4.4308500e+00 -1.0481000e+00 -7.8117514e-01\n",
            " -1.6870000e+00  1.9781501e+00  1.4894226e+00 -2.8325254e-01\n",
            " -1.4800999e+00  1.4303375e+00  2.6068749e+00 -1.3935680e+00\n",
            " -4.5071498e-01  1.8592875e+00  6.0194993e-01 -2.0355899e+00\n",
            "  5.3853750e+00  3.3568425e+00 -2.6558499e+00 -2.5876875e+00\n",
            " -4.1877502e-01  1.1819749e+00 -1.0135007e-01 -1.6391747e+00\n",
            " -7.5115502e-01 -2.4396350e+00 -5.0018353e+00  4.4182479e-02\n",
            " -1.1361099e+00  3.4045234e+00  4.4069252e+00  1.5867125e+00\n",
            "  7.3212752e+00 -6.2377250e-01 -3.5406952e+00 -1.5487249e+00\n",
            " -2.7915027e+00  4.5692497e-01 -2.8675752e+00 -2.1574497e+00\n",
            "  3.5327253e+00  2.9429674e+00 -3.0028498e+00  4.0561576e+00\n",
            " -2.2131751e+00 -2.7301099e+00  2.2525599e+00  6.7574859e-02\n",
            " -2.9405074e+00  1.8029499e+00 -1.1789126e+00 -2.1746502e+00\n",
            " -2.1985504e-01  1.1351575e+00  3.9773331e+00 -1.4294751e+00\n",
            "  2.7083826e-01  2.8169625e+00  3.3689499e+00 -3.6275029e-02\n",
            " -6.6733754e-01 -2.0622499e+00  5.5217499e-01  2.1563876e+00\n",
            "  5.8253503e+00 -5.5494246e+00 -3.5856503e-01 -1.6503401e+00\n",
            " -1.3458250e+00 -1.4840007e-01  1.7622524e+00 -9.1479999e-01\n",
            "  2.1465900e+00  4.4622073e+00  3.2821400e+00  1.8457750e+00\n",
            " -1.8648493e-01  9.6283495e-01 -1.4834499e+00  4.0102500e-01\n",
            " -2.9797997e+00  7.9937494e-01  2.4522400e+00 -1.5166250e+00\n",
            " -3.7715238e-01  2.3985500e+00  3.3255002e-01  1.7986224e+00\n",
            " -6.8490005e-01 -5.1091760e-01 -1.8716326e+00 -8.0151993e-01\n",
            " -1.2196251e+00 -2.4377999e+00 -8.4822536e-01  4.4465375e+00\n",
            "  1.9551001e+00 -4.5647252e-01  1.1451000e+00 -2.7702999e+00\n",
            " -5.0074500e-01 -1.2053250e+00 -5.6294746e+00  1.9835000e+00\n",
            " -2.7191000e+00 -1.5045950e+00  6.9217503e-01  2.5230401e+00\n",
            " -2.1575000e+00 -1.4835875e+00  3.3636250e+00 -1.8662750e+00\n",
            " -2.0677674e+00  1.4370599e+00  1.0521392e+00  2.1033750e+00\n",
            " -2.1464827e+00  5.6450999e-01  5.3212500e-01 -8.3847724e-02\n",
            " -6.6377509e-01  6.8043244e-01 -2.0621850e+00  2.8536501e+00\n",
            " -1.7352247e+00 -2.8443000e+00 -5.3201753e-01  8.3302242e-01\n",
            "  3.7822717e-01  9.0502751e-01 -9.2559004e-01  2.6364100e-01\n",
            " -2.1059022e+00 -4.7094274e+00 -2.3757493e-01  1.3409747e-01\n",
            " -1.4695925e+00  1.1836300e+00 -1.7678249e+00 -2.0474751e+00\n",
            " -3.1015801e+00 -2.7474751e+00  2.3939500e+00  2.9119998e-01\n",
            " -6.4154994e-01  2.9983025e+00  2.3853002e+00 -3.8257499e+00\n",
            "  4.6561250e-01  2.4625850e+00 -4.1938251e-01  6.9829524e-01\n",
            " -7.1579993e-01 -1.4624953e-02  3.2372375e+00 -3.2502999e+00\n",
            "  4.5349836e-02  4.1063027e+00 -2.2001500e+00 -1.6467290e+00\n",
            "  3.1262751e+00  1.4225700e+00  3.6304951e-02  1.4041975e+00\n",
            " -1.5605751e+00  2.3753252e+00  2.6392999e+00 -1.5464250e+00\n",
            " -5.9728498e+00  1.9010249e+00 -1.8664751e+00  5.6060200e+00\n",
            " -9.5827496e-01 -1.9006126e+00 -4.8451276e+00 -5.8231246e-01\n",
            " -7.2317505e-01 -2.2110374e+00  8.1549001e-01 -1.0414025e+00\n",
            "  1.9058951e+00 -3.8605497e+00  3.5286000e+00  1.3662599e+00\n",
            "  2.2550497e+00  2.5063176e+00 -2.7124995e-01  1.9068251e+00\n",
            " -2.3303626e+00 -3.5958242e-01  7.9588258e-01 -1.6820974e+00\n",
            " -3.7828848e+00  2.2385600e+00 -2.3069249e-01  3.8866749e+00\n",
            " -2.9949999e+00 -7.2774887e-02 -5.2936137e-01  2.3862777e+00\n",
            "  2.7844000e+00  2.0868599e+00 -1.0202500e+00 -6.6188755e+00\n",
            "  2.5358500e+00  2.3292500e-01 -1.5609975e+00  1.4913775e+00\n",
            "  4.9717754e-01  6.1425052e+00 -9.3077004e-01 -1.0970299e+00\n",
            " -3.2835951e+00 -4.0366502e+00  2.8092499e+00  5.4461503e-01\n",
            "  5.1136999e+00 -4.7508508e-01 -3.0958500e+00 -1.6869251e+00\n",
            "  5.5714927e+00 -5.8892751e-01 -2.1862252e+00  7.2488189e-04\n",
            " -5.1041250e+00 -2.0981116e+00 -3.4806490e-01 -1.5959325e+00\n",
            " -4.2672509e-01  1.1591926e+00 -3.7716749e+00  2.1917500e+00\n",
            "  2.8775399e+00  3.8451598e+00  4.2834749e+00  2.1570098e+00\n",
            "  2.5055449e+00 -1.2231750e+00  4.1285264e-01  1.1988211e+00\n",
            " -4.9739499e+00  1.0778250e+00  4.2271227e-01 -3.8091974e+00\n",
            " -3.7465799e+00 -1.0162874e+00 -1.5726924e+00 -3.8487256e-01\n",
            "  2.0939450e+00 -3.7680500e+00  2.6195997e-01  2.4638376e+00\n",
            " -1.9473826e+00 -1.5511725e+00  3.0020747e+00  4.0775223e+00\n",
            "  4.7141755e-01 -1.4983499e-01  2.5353000e+00  2.0879149e+00\n",
            " -1.3202243e-01 -2.3845255e-01  4.0010076e+00  1.6600013e-02\n",
            "  4.4546151e+00 -1.3000700e+00 -2.6352043e+00  1.1399500e+00\n",
            "  1.8315576e+00 -2.9688001e+00 -7.6453247e+00  8.4300494e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "clf_svm_wv=svm.SVC(kernel='linear')\n",
        "clf_svm_wv.fit(train_x_word_vectors, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "zOGwyyNdZFiH",
        "outputId": "10e172b6-cf5f-482e-baa3-fa7f542b8ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x=[\"i love the story\"]\n",
        "test_docs=[nlp(text) for text in test_x]\n",
        "test_x_word_vectors=[x.vector for x in test_docs]\n",
        "clf_svm_wv.predict(test_x_word_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or5kX9MRaubQ",
        "outputId": "b2637065-fd4e-44e2-ff5c-a8007abca354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['BOOKS'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x=[\"these earings hurt\"]\n",
        "test_docs=[nlp(text) for text in test_x]\n",
        "test_x_word_vectors=[x.vector for x in test_docs]\n",
        "clf_svm_wv.predict(test_x_word_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXt3smefb2Nf",
        "outputId": "81a99637-b665-40a7-a52b-47c37c885a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CLOTHING'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. Loading Word Embeddings Model:\n",
        "   The code starts by importing the `spacy` library, which helps us work with natural language text. We then load a pre-trained English word embeddings model (`en_core_web_md`). Word embeddings are numerical representations of words that capture their meaning and context.\n",
        "\n",
        "2. Training Data:\n",
        "   The `train_x` variable contains a list of text samples that we want to use for training a machine learning model. Each text sample is like a sentence or a paragraph.\n",
        "\n",
        "3. Converting Text to Word Vectors:\n",
        "   We use the loaded model to process each text sample in the training data (`train_x`). This process converts the text into a structured format, and for each word in the text, it gives us a unique numerical vector that represents that word's meaning.\n",
        "\n",
        "4. Word Vectors for Training Data:\n",
        "   After processing the training data, we collect all the word vectors for each text sample. We create a new list called `train_x_word_vectors` that contains these word vectors for each text sample. Each text sample is now represented by a set of numerical vectors instead of just words.\n",
        "\n",
        "5. Accessing Word Vector for a Text Sample:\n",
        "   The code prints the word vector for the first document in the `docs` list. The `docs` list contains the processed text samples, and we access the word vector for the first sample using `docs[0].vector`.\n",
        "\n",
        "6. Test Data:\n",
        "   We have a new piece of text data `test_x`, which is \"i love the story\". This is a single text sample that we want to use to test our trained machine learning model.\n",
        "\n",
        "7. Converting Test Text to Word Vector:\n",
        "   Just like with the training data, we process the test data (`test_x`) and convert it into a word vector using the same loaded model. We create a new list called `test_x_word_vectors`, which contains the word vector for the test data.\n",
        "\n",
        "8. Using the Trained Model for Prediction:\n",
        "   The code uses a previously trained SVM classifier (`clf_svm_wv`, not shown in the code snippet) to make a prediction on the test data represented as word vectors (`test_x_word_vectors`). The SVM classifier has learned from the word vectors of the training data and can now predict the class label (category or sentiment) for the test data.\n",
        "\n",
        "In simple terms, the code uses a language model to convert text into meaningful numerical vectors. Then, it uses those vectors to train a machine learning model to understand the relationships between words in the training data. Finally, it uses the trained model to predict the meaning or category of new text data (test data)."
      ],
      "metadata": {
        "id": "Fi2l1ZUWuIBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REGEXES AND PATTERN MATCHING**"
      ],
      "metadata": {
        "id": "ku75xXEUE8tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "regexp=re.compile(r\"^ab[^\\s]*cd$\")\n",
        "phrases=['abcd','xxx','abxxxcd','ab cd']\n",
        "matches=[]\n",
        "for p in phrases:\n",
        "  if re.match(regexp,p):\n",
        "    matches.append(p)\n",
        "print(matches)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLkk7lz0dKz4",
        "outputId": "1c7b75f1-c845-4224-858b-7aa7f1c7ef6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abcd', 'abxxxcd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code compiles a regular expression pattern using the re.compile() function. The pattern r\"^ab[^\\s]*cd$\" represents the regular expression:\n",
        "\n",
        "^: Asserts the start of the string.\n",
        "ab: Matches the characters \"ab\" literally.\n",
        "[^\\s]*: Matches zero or more occurrences of any character except whitespace.\n",
        "cd: Matches the characters \"cd\" literally.\n",
        "$: Asserts the end of the string."
      ],
      "metadata": {
        "id": "b2YQWLG_Fe1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you use re.search() instead of re.match() in the code, the behavior will change slightly. While re.match() only checks for a match at the beginning of the string, re.search() searches for the pattern anywhere within the string. The match can occur at any position in the string, not just at the beginning."
      ],
      "metadata": {
        "id": "crTSc9uwGKo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#REGULAR SYMBOLS USED\n",
        ". (Dot): Matches any character except a newline.\n",
        "\n",
        "* (Asterisk): Matches zero or more occurrences of the previous character or group.\n",
        "\n",
        "+ (Plus): Matches one or more occurrences of the previous character or group.\n",
        "\n",
        "? (Question Mark): Matches zero or one occurrence of the previous character or group.\n",
        "\n",
        "| (Vertical Bar or Pipe): Acts as an OR operator, matching either the expression before or after it.\n",
        "\n",
        "^ (Caret): Matches the start of a string.\n",
        "\n",
        "$ (Dollar Sign): Matches the end of a string.\n",
        "\n",
        "[ ] (Square Brackets): Defines a character class and matches any character within the brackets. For example, [aeiou] matches any vowel.\n",
        "\n",
        "[^ ] (Caret inside Square Brackets): Defines a negated character class and matches any character not listed within the brackets.\n",
        "\n",
        "( ) (Parentheses): Groups characters together, allowing for quantifiers to be applied to the entire group.\n",
        "\n",
        "{m} (Curly Braces): Matches exactly 'm' occurrences of the previous character or group.\n",
        "\n",
        "{m, n} (Curly Braces with Range): Matches between 'm' and 'n' occurrences of the previous character or group.\n",
        "\n",
        "\\ (Backslash): Escapes special characters to match them literally. For example, \\. matches a period (dot) instead of any character.\n",
        "\n",
        "\\d, \\D: Matches a digit (0-9), or any character except a digit.\n",
        "\n",
        "\\w, \\W: Matches a word character (alphanumeric or underscore), or any character except a word character.\n",
        "\n",
        "\\s, \\S: Matches a whitespace character (space, tab, newline), or any character except a whitespace character.\n",
        "\n",
        "\\b, \\B: Matches a word boundary, or a position that is not a word boundary."
      ],
      "metadata": {
        "id": "RbNhMHjzGtjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEMMING OR LEMMATIZATION**"
      ],
      "metadata": {
        "id": "LR4laUSrHOod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "VE__UIlsE1z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a21dd86-0d0d-40a8-c85a-c9b996bc4191"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming"
      ],
      "metadata": {
        "id": "A3oH-lZiu2F4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "phrase = \"reading the books\"\n",
        "words = word_tokenize(phrase)\n",
        "\n",
        "stemmed_words = []\n",
        "for word in words:\n",
        "  stemmed_words.append(stemmer.stem(word))\n",
        "\n",
        "\" \".join(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QrMDxsmmuk2y",
        "outputId": "71685dfd-0725-4ea7-db77-68910e9a1c16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'read the book'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization:\n",
        "It is the process of reducing words to their base or dictionary form. In your code, you're lemmatizing the words in the phrase \"reading the books\" and then joining them back together."
      ],
      "metadata": {
        "id": "SRJxtPQJu6Qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "phrase = \"reading the books\"\n",
        "words = word_tokenize(phrase)\n",
        "\n",
        "lemmatized_words = []\n",
        "for word in words:\n",
        "  lemmatized_words.append(lemmatizer.lemmatize(word, pos='v'))\n",
        "\n",
        "\" \".join(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fg4uzSIRu4e7",
        "outputId": "37016dc0-7d62-4ca2-bb87-6b9fc4713307"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'read the book'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#STOPWORDS REMOVAL\n"
      ],
      "metadata": {
        "id": "lemu8ahJx2ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "phrase = \"Here is an example sentence demonstrating the removal of stopwords\"\n",
        "\n",
        "words = word_tokenize(phrase)\n",
        "\n",
        "stripped_phrase = []\n",
        "for word in words:\n",
        "  if word not in stop_words:\n",
        "    stripped_phrase.append(word)\n",
        "\n",
        "\" \".join(stripped_phrase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "s_wXdFRyvByG",
        "outputId": "83ef24b6-5f5b-4c73-c522-a653d9ae6a7d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here example sentence demonstrating removal stopwords'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mECkhv1kyYAu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}